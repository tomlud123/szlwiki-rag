import time
import torch
from langchain_huggingface import HuggingFaceEmbeddings

# ğŸ”§ Uruchamianie na: CPU
# â±ï¸  Czas: 76.10 sekundy
#
# ğŸ”§ Uruchamianie na: CUDA
# â±ï¸  Czas: 7.69 sekundy
# ğŸ§  CUDA dostÄ™pna: True
# ğŸ“Š UÅ¼ywana karta: NVIDIA GeForce RTX 5070
# ğŸ’¾ ZuÅ¼ycie pamiÄ™ci: 2143.9 MB

# losowe dane do embedowania
N = 10_000
texts = ["To jest testowy tekst nr {}".format(i) for i in range(N)]

def run_benchmark(device: str):
    print(f"\nğŸ”§ Uruchamianie na: {device.upper()}")
    model = HuggingFaceEmbeddings(
        model_name="intfloat/multilingual-e5-large",
        model_kwargs={"device": device},
        encode_kwargs={"normalize_embeddings": True},
    )

    # ğŸ”¹ Pomiar czasu
    start = time.perf_counter()
    _ = model.embed_documents(texts)
    end = time.perf_counter()

    duration = end - start
    print(f"â±ï¸  Czas: {duration:.2f} sekundy")

    if device == "cuda":
        # ğŸ”¹ PokaÅ¼ dodatkowe informacje GPU
        print(f"ğŸ§  CUDA dostÄ™pna: {torch.cuda.is_available()}")
        print(f"ğŸ“Š UÅ¼ywana karta: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ ZuÅ¼ycie pamiÄ™ci: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")

if __name__ == "__main__":
    run_benchmark("cpu")
    run_benchmark("cuda")
